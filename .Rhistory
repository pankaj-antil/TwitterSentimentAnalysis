print("abc");
# Create data for the graph.
x <-  c(71, 32, 58,41)
labels <-  c("Hindu","Muslim","Sikh","Christian")
piepercent<- round(100*x/sum(x), 1)
# Give the chart file a name.
png(file = "piechart")
# Plot the chart.
pie(x, labels = piepercent, main = "Community pie chart",col = rainbow(length(x)))
legend("topright", c("Hindu","Muslim","Sikh","Christian"), cex = 0.8,
fill = rainbow(length(x)))
# Save the file.
dev.off()
source('~/piechart.r')
barplot(x)
boxplot(x)
png(file = "boxplot")
png(file = "boxplot.png")
boxplot(x)
boxplot(a)
x <- c(21, 62, 10, 53)
labels <- c("London", "New York", "Singapore", "Mumbai")
pie(x,labels)
pie(x,labels)
install.packages('twitteR',dependencies=T)
install.packages('twitteR',dependencies=T)
library(plyr)
install.packages('plyr',dependencies=T)
tweets=searchTwitter("#abortion",n=1500)
install.packages(sentiment)
install.packages('sentiment',dependencies=T)
setwd("c:/sentiment")
library(twitteR)
tweets=searchTwitter("#abortion",n=1500)
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(twitteR)
library(plyr)
library(ROAuth)
install.packages('ROAuth',dependencies=T)
library(ROAuth)
library(stringr)
library(ggplot2)
install.packages('ggplot2',dependencies=T)
library(ggplot2)
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(RCurl)
library(twitteR)
library(plyr)
library(ROAuth)
library(stringr)
library(ggplot2)
library(ggplot2)
library(RCurl)
delta.tweets = searchTwitter('@delta',n=1500)
access_token_secret <- "k0ekbRRt5ZYODsITpy7z7psKfesu5VEDXLmMciXgVtGBp"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(RCurl)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
api_key <- "	TJf8q021zOvQWTTOSQUTsId9u"
api_secret <- "V5O68uXAZ6UkiSmIVO6ouuBzvpEpvE0TZRVLgrAP3JTPBu8Ax8"
access_token <- "851486451598491650-4PFZ0dSVBrqbxDYgTqzHxmmpUx5SPlB"
access_token_secret <- "k0ekbRRt5ZYODsITpy7z7psKfesu5VEDXLmMciXgVtGBp"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
<- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
api_key <- "	TJf8q021zOvQWTTOSQUTsId9u"
api_secret <- "V5O68uXAZ6UkiSmIVO6ouuBzvpEpvE0TZRVLgrAP3JTPBu8Ax8"
access_token <- "851486451598491650-4PFZ0dSVBrqbxDYgTqzHxmmpUx5SPlB"
access_token_secret <- "k0ekbRRt5ZYODsITpy7z7psKfesu5VEDXLmMciXgVtGBp"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
neg.words = c(negText, 'wtf', 'wait', 'waiting','epicfail', 'mechanical')
library(wordcloud)
installed.packages('wordcloud',dependencies=T)
installed.packages('wordcloud')
library(wordcloud)
library(RColorBrewer)
install.packages('wordcloud')
library(wordcloud)
library(RColorBrewer)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
api_key <- "	TJf8q021zOvQWTTOSQUTsId9u"
api_secret <- "V5O68uXAZ6UkiSmIVO6ouuBzvpEpvE0TZRVLgrAP3JTPBu8Ax8"
access_token <- "851486451598491650-4PFZ0dSVBrqbxDYgTqzHxmmpUx5SPlB"
access_token_secret <- "k0ekbRRt5ZYODsITpy7z7psKfesu5VEDXLmMciXgVtGBp"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
packages.install('base64enc',dependencies=T)
package.install('base64enc',dependencies=T)
install.packages('base64enc',dependencies=T)
library(base64enc)
library(RColorBrewer)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
api_key <- "	TJf8q021zOvQWTTOSQUTsId9u"
api_secret <- "V5O68uXAZ6UkiSmIVO6ouuBzvpEpvE0TZRVLgrAP3JTPBu8Ax8"
access_token <- "851486451598491650-4PFZ0dSVBrqbxDYgTqzHxmmpUx5SPlB"
access_token_secret <- "k0ekbRRt5ZYODsITpy7z7psKfesu5VEDXLmMciXgVtGBp"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
posText <- read.delim("…/positive-words.txt", header=FALSE, stringsAsFactors=FALSE)
library(base64enc)
library(RColorBrewer)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
api_key <- "	TJf8q021zOvQWTTOSQUTsId9u"
api_secret <- "V5O68uXAZ6UkiSmIVO6ouuBzvpEpvE0TZRVLgrAP3JTPBu8Ax8"
access_token <- "851486451598491650-4PFZ0dSVBrqbxDYgTqzHxmmpUx5SPlB"
access_token_secret <- "k0ekbRRt5ZYODsITpy7z7psKfesu5VEDXLmMciXgVtGBp"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
access_token_secret <- "k0ekbRRt5ZYODsITpy7z7psKfesu5VEDXLmMciXgVtGBp"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(twitteR)
library(plyr)
library(ROAuth)
library(stringr)
library(ggplot2)
library(ggplot2)
library(RCurl)
library(wordcloud)
library(base64enc)
library(RColorBrewer)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
api_key <- "fXUA8zOUKyTVSAzBs1aodrwjR"
api_secret <- "VpCwqWKR4obdAOxTtT4ttCCMzNUuGqgCoduui6aXVIDdqklYI0"
access_token <- "851486451598491650-4PFZ0dSVBrqbxDYgTqzHxmmpUx5SPlB"
access_token_secret <- "k0ekbRRt5ZYODsITpy7z7psKfesu5VEDXLmMciXgVtGBp"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
some_tweets = searchTwitter("starbucks", n=1500, lang="en")
some_txt = sapply(some_tweets, function(x) x$getText())
some_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", some_txt)
some_txt = gsub("@\\w+", "", some_txt)
some_txt = gsub("[[:punct:]]", "", some_txt)
some_txt = gsub("[[:digit:]]", "", some_txt)
some_txt = gsub("http\\w+", "", some_txt)
some_txt = gsub("^\\s+|\\s+$", "", some_txt)
some_txt = sapply(some_txt, try.error)
some_txt = some_txt[!is.na(some_txt)]
names(some_txt) = NULL
class_emo = classify_emotion(some_txt, algorithm="bayes", prior=1.0)
library(sentiment)
install.packages('setiment',dependencies=T)
library(twitteR)
library(plyr)
library(ROAuth)
library(stringr)
library(ggplot2)
library(ggplot2)
library(RCurl)
library(wordcloud)
library(base64enc)
library(RColorBrewer)
tweets=searchTwitter("#abortion",n=1500)
length(tweets)
tweets.text=laply(tweets,fuction(t)t$getText())
tweets.text=laply(tweets,fuction(t) t$getText())
tweets.text=laply(tweets,function(t) t$getText())
pos=scan('positive-words.text',what='character',comment.char';')
pos=scan('positive-words.text',what='character',comment.char=';')
pos=scan('positive-words.txt',what='character',comment.char=';')
pos=scan('positive-words.txt',what='character',comment.char=';')
pos=scan('positive_words.txt',what='character',comment.char=';')
pos=scan('positive-words.txt',what='character',comment.char=';')
library(twitteR)
library(plyr)
library(ROAuth)
library(stringr)
library(ggplot2)
library(ggplot2)
library(RCurl)
library(wordcloud)
library(base64enc)
library(RColorBrewer)
tweets=searchTwitter("#abortion",n=1500)
library(twitteR)
library(plyr)
library(ROAuth)
library(stringr)
library(ggplot2)
library(ggplot2)
library(RCurl)
library(wordcloud)
library(base64enc)
library(RColorBrewer)
tweets=searchTwitter("#abortion",n=1500)
length(tweets)
tweets.text=laply(tweets,function(t) t$getText())
pos=scan('positive-words.txt',what='character',comment.char=';')
library(twitteR)
library(plyr)
library(ROAuth)
library(stringr)
library(ggplot2)
library(ggplot2)
library(RCurl)
library(wordcloud)
library(base64enc)
library(RColorBrewer)
options(RCurlOptions = list(cainfo = system.file(“CurlSSL”, “cacert.pem”, package = “RCurl”)))
#----------AUTHENTICATION----------------
getwd()
setwd("C:/Users/Bindu/SentiTwitterR")
getwd()
library(twitteR)
library(plyr)
library(ROAuth)
library(stringr)
library(ggplot2)
library(ggplot2)
library(RCurl)
library(wordcloud)
library(base64enc)
library(RColorBrewer)
library(e1071)
consumer_key <- "o528f9AJqrCuTdnY9MvdR2wRf"
consumer_secret <- "N45TcVtbqTDjahtpzXQmUHMVltehxDvfjhCW8A5zHb1KXGa2pK"
access_token <- "851486451598491650-BCanmtomQ48Olkm6QFBXM1rt4SK9Etg"
access_token_secret <- "V949w4FmfyEwBQYBxVhVK4DIVmWegFQsdc7qdyE92QsVf"
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_token_secret)
getwd()
setwd("C:/Users/Bindu/SentiTwitterR")
getwd()
library(twitteR)
library(plyr)
library(ROAuth)
library(stringr)
library(ggplot2)
library(ggplot2)
library(RCurl)
library(wordcloud)
library(base64enc)
library(RColorBrewer)
library(e1071)
consumer_key <- "o528f9AJqrCuTdnY9MvdR2wRf"
consumer_secret <- "N45TcVtbqTDjahtpzXQmUHMVltehxDvfjhCW8A5zHb1KXGa2pK"
access_token <- "851486451598491650-BCanmtomQ48Olkm6QFBXM1rt4SK9Etg"
access_token_secret <- "V949w4FmfyEwBQYBxVhVK4DIVmWegFQsdc7qdyE92QsVf"
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_token_secret)
getwd()
setwd("C:/Users/Bindu/SentiTwitterR")
getwd()
library(twitteR)
library(plyr)
library(ROAuth)
library(stringr)
library(ggplot2)
library(ggplot2)
library(RCurl)
library(wordcloud)
library(base64enc)
library(RColorBrewer)
library(e1071)
consumer_key <- "x7BtUiWPorSSSqoLud3ngZ9Ky"
consumer_secret <- "62HrN5uULFTEYAjFI5C8MeoPwwWKPq2Fr6l9XscjUCZZTouSCI"
access_token <- "851486451598491650-BCanmtomQ48Olkm6QFBXM1rt4SK9Etg"
access_token_secret <- "V949w4FmfyEwBQYBxVhVK4DIVmWegFQsdc7qdyE92QsVf"
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_token_secret)
getwd()
setwd("C:/Users/Bindu/SentiTwitterR")
getwd()
library(twitteR)
library(plyr)
library(ROAuth)
library(stringr)
library(ggplot2)
library(ggplot2)
library(RCurl)
library(wordcloud)
library(base64enc)
library(RColorBrewer)
library(e1071)
consumer_key <- "x7BtUiWPorSSSqoLud3ngZ9Ky"
consumer_secret <- "62HrN5uULFTEYAjFI5C8MeoPwwWKPq2Fr6l9XscjUCZZTouSCI"
access_token <- "851486451598491650-4X9dU3oOjWvQM7dy6CophZE801uzDVw"
access_token_secret <- "6k8ArlQT8RcZxlOMpXjBv8eP2Wogh7ZlL51YoUqeVKsmX"
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_token_secret)
cred = OAuthFactory$new(consumerKey=consumer_key,
consumerSecret=consumer_secret,
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
cred$handshake(cainfo="cacert.pem")
tweets=searchTwitter("#modi",n=1000)
tweets=searchTwitter("#modi",n=1000)
getwd()
getwd()
library(stringr)
library(ggplot2)
library(ggplot2)
library(RCurl)
library(wordcloud)
library(base64enc)
library(RColorBrewer)
library(e1071)
consumer_key <- "P7uGaiQFBGUXxKfT9xlQxKGy4"
consumer_secret <- "vDfiySuheFdFakWspRhkOaoVroOujmeMK7OsttsMfAe51V6NLK"
access_token <- "851486451598491650-yarCnAzcA6tHwt2w0kpeTlHCxiry8PN"
access_token_secret <- "j3t818L1tEd99OpcTMh9Ngj6x1Jw9o2L4iL0965Js8C2C"
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_token_secret)
cred = OAuthFactory$new(consumerKey=consumer_key,
consumerSecret=consumer_secret,
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
cred$handshake(cainfo="cacert.pem")
tweets=searchTwitter("#modi",n=1000)
modi.tweets = searchTwitter("modi", n=150)
df <- do.call("rbind", lapply(modi.tweets, as.data.frame))
df$text <- sapply(df$text,function(row) iconv(row, "latin1", "ASCII", sub="")) #remove emoticon
df$text = gsub("(f|ht)tp(s?)://(.*)[.][a-z]+", "", df$text) #remove URL
sample <- df$text
pos.words = scan('C:/Users/Bindu/SentiTwitterR/positive-words.txt', what='character', comment.char=';')
neg.words = scan('C:/Users/Bindu/SentiTwitterR/negative-words.txt', what='character', comment.char=';')
pos.words=c(pos.words, 'Congrats', 'prizes', 'prize', 'thanks', 'thnx', 'Grt', 'gr8', 'plz', 'trending', 'recovering', 'brainstorm', 'leader')
neg.words = c(neg.words, 'Fight', 'fighting', 'wtf', 'arrest', 'no', 'not')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)  #removes decimal number
sentence = gsub('\n','',sentence)    #removes new lines
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)  #changes a list to character vector
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp = sum(pos.matches)
nn = sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1 = c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new = lapply(list, `[[`, 1)
pp1 = lapply(list, `[[`, 2)
nn1 = lapply(list, `[[`, 3)
scores.df = data.frame(score = score_new, text=sentences)
positive.df = data.frame(Positive = pp1, text=sentences)
negative.df = data.frame(Negative = nn1, text=sentences)
list_df = list(scores.df, positive.df, negative.df)
return(list_df)
}
result = score.sentiment(sample, pos.words, neg.words)
library(reshape)
install.packages('reshape',dependencies=T)
library(reshape)
library(reshape)
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]
test1$text=NULL
test2$text=NULL
test3$text=NULL
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative')
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)
table_final=data.frame(Text=table1$Text, Score=table1$value, Positive=table2$value, Negative=table3$value)
posSc=table_final$Positive
negSc=table_final$Negative
table_final$PosPercent = posSc/ (posSc+negSc)
pp = table_final$PosPercent
pp[is.nan(pp)] <- 0
table_final$PosPercent = pp
table_final$NegPercent = negSc/ (posSc+negSc)
nn = table_final$NegPercent
nn[is.nan(nn)] <- 0
table_final$NegPercent = nn
hist(table_final$Positive, col=rainbow(10))
hist(table_final$Negative, col=rainbow(10))
hist(table_final$Score, col=rainbow(10))
slices <- c(sum(table_final$Positive), sum(table_final$Negative))
labels <- c("Positive", "Negative")
library(plotrix)
install.packages('plotrix',dependencies=T)
library(plotrix)
library(plotrix)
library(plotrix)
pie3D(slices, labels = labels, col=rainbow(length(labels)),explode=0.00, main="Sentiment Analysis")
hist(table_final$Positive, col=rainbow(10))
hist(table_final$Negative, col=rainbow(10))
hist(table_final$Score, col=rainbow(10))
slices <- c(sum(table_final$Positive), sum(table_final$Negative))
labels <- c("Positive", "Negative")
library(plotrix)
pie3D(slices, labels = labels, col=rainbow(length(labels)),explode=0.00, main="Sentiment Analysis")
library(twitteR)
tw = userTimeline("BarackObama", n = 3200)
tw = twListToDF(tw)
vec1 = tw$text
hash.pattern = "#[[:alpha:]]+"
have.hash = grep(x = vec1, pattern = hash.pattern) #stores the indices of the tweets which have hashes
hash.matches = gregexpr(pattern = hash.pattern,
text = vec1[have.hash])
extracted.hash = regmatches(x = vec1[have.hash], m = hash.matches) #the actual hashtags are stored here
df = data.frame(table(tolower(unlist(extracted.hash)))) #dataframe formed with var1(hashtag), freq of hashtag
colnames(df) = c("tag","freq")
df = df[order(df$freq,decreasing = TRUE),]
dat = head(df,50)
dat2 = transform(dat,tag = reorder(tag,freq)) #reorder it so that highest freq is at the top
library(ggplot2)
p = ggplot(dat2, aes(x = tag, y = freq)) + geom_bar(stat="identity", fill = "blue")
p + coord_flip() + labs(title = "Hashtag frequencies in the tweets of the Obama team (@BarackObama)")
a_trends = availableTrendLocations()
woeid = a_trends[which(a_trends$name=="Ottawa"),3]
canada_trend = getTrends(woeid)
trends = canada_trend[1:2]
dat <- cbind(trends$name)
dat2 <- unlist(strsplit(dat, split=", "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[-dat3]
dat4
modi_text = sapply(modi.tweets, function(x) x$getText()) #sapply returns a vector
df <- do.call("rbind", lapply(modi.tweets, as.data.frame)) #lapply returns a list
modi_text <- sapply(df$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
str(trump_text) #gives the summary/internal structure of an R object
str(modi_text) #gives the summary/internal structure of an R object
library(tm) #tm: text mining
install.packages('tm',dependencies=T)
library(tm) #tm: text mining
modi_corpus <- Corpus(VectorSource(trump_text)) #corpus is a collection of text documents
modi_corpus <- Corpus(VectorSource(modi_text)) #corpus is a collection of text documents
modi_corpus
inspect(modi_corpus[1])
library(wordcloud)
modi_clean <- tm_map(modi_corpus, removePunctuation)
modi_clean <- tm_map(modi_clean, removeWords, stopwords("english"))
modi_clean <- tm_map(modi_clean, removeNumbers)
modi_clean <- tm_map(modi_clean, stripWhitespace)
wordcloud(modi_clean, random.order=F,max.words=80, col=rainbow(50), scale=c(3.5,1))
